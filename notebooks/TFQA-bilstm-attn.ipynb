{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pickle\n",
    "import json\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pymongo import MongoClient\n",
    "from spacy.tokens import Doc\n",
    "from spacy.attrs import ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize spacy language with pretrained model\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "spacy.vocab.link_vectors_to_models(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 872422 QA's in mongoDB collection...\n"
     ]
    }
   ],
   "source": [
    "# open MongoDB and collections\n",
    "MONGO_URI = 'mongodb://barnwaldo:shakeydog@192.168.248.4:27017/?authSource=admin'\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client['tfqa']\n",
    "qa = db['qa']\n",
    "num = qa.count_documents({})\n",
    "print(\"There are {} QA's in mongoDB collection...\".format(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents read from MongoDB: 872422\n"
     ]
    }
   ],
   "source": [
    "question_list = []\n",
    "answer_list = []\n",
    "label_list = []\n",
    "# mongo document --> _id, question, long_answer, top_level, label (0 or 1)\n",
    "for doc in qa.find():\n",
    "    question_list.append(doc['question'].replace('[UNK]', 'UNK'))\n",
    "    answer_list.append(doc['long_answer'].replace('[UNK]', 'UNK'))\n",
    "    label_list.append(doc['label'])\n",
    "print(\"Documents read from MongoDB: {}\".format(len(question_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start nlp pipe for question tokenizer...\n",
      "Complete nlp pipe for question tokenizer...\n",
      "Start nlp pipe for answer tokenizer...\n",
      "Complete nlp pipe for answer tokenizer...\n"
     ]
    }
   ],
   "source": [
    "max_question_len = 35\n",
    "max_answer_len = 200\n",
    "pad = nlp('UNK').to_array([ID])\n",
    "qst = np.full((num, max_question_len), 0, dtype='int32')\n",
    "ans = np.full((num, max_answer_len), 0, dtype='int32')\n",
    "lab = np.full((num, 1), 0, dtype='int32')\n",
    "\n",
    "# token then pad questions and long_answers before tokenization with unknown token\n",
    "print(\"Start nlp pipe for question tokenizer...\")\n",
    "idx = 0\n",
    "for doc in nlp.pipe(question_list, disable=[\"tagger\", \"parser\", \"ner\"]):\n",
    "    tq = doc.to_array([ID])\n",
    "    tq[tq == pad] = 0\n",
    "    qst[idx, 0: len(tq)] = tq if len(tq) < max_question_len else tq[0: max_question_len]\n",
    "    idx += 1\n",
    "print(\"Complete nlp pipe for question tokenizer...\")\n",
    "\n",
    "print(\"Start nlp pipe for answer tokenizer...\")\n",
    "idx = 0\n",
    "for doc in nlp.pipe(answer_list, disable=[\"tagger\", \"parser\", \"ner\"]):\n",
    "    ta = doc.to_array([ID])\n",
    "    ta[ta == pad] = 0\n",
    "    ans[idx, 0: len(ta)] = ta if len(ta) < max_answer_len else ta[0: max_answer_len]\n",
    "    lab[idx, 0] = label_list[idx]\n",
    "    idx += 1\n",
    "print(\"Complete nlp pipe for answer tokenizer...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Matrix shape: (684831, 300)\n",
      "Embedding Index length: 684830\n",
      "Embedding Matrix dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# setup embedding matrix from existing Spacy Vocabulary (could use Bert or Glove)  -- used for pre-existing embedding or to determine length of vocabulary for training embedding layer\n",
    "embedding_index = {}\n",
    "for key, vector in nlp.vocab.vectors.items():\n",
    "    row = nlp.vocab.vectors.find(key=key) \n",
    "    word = nlp.vocab.strings[key]\n",
    "    embedding_index[word] = row\n",
    "    # print(key, nlp.vocab.strings[key], row, vector)\n",
    "\n",
    "embedding_matrix = nlp.vocab.vectors.data\n",
    "embedding_shape = embedding_matrix.shape\n",
    "print('Embedding Matrix shape:', embedding_shape)\n",
    "print('Embedding Index length:', len(embedding_index))\n",
    "print('Embedding Matrix dtype:', embedding_matrix.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bidirectional LSTM model with multihead (self) attention for both questions and answered concatenated thru a final linear layer with activation \n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import models, initializers, Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "# from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Embedding, ReLU, LSTM, Bidirectional, Lambda, LayerNormalization, TimeDistributed, Activation\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, Concatenate\n",
    "\n",
    "# implement (dot product) attention with scaling\n",
    "class Attention():\n",
    "    def __init__(self, dim, dropout=0.1):\n",
    "        self.temperature = np.sqrt(dim)\n",
    "        self.dropout = Dropout(dropout)\n",
    "    def __call__(self, q, k, v, mask):\n",
    "        attn = Lambda(lambda x: K.batch_dot(x[0], x[1], axes=[2,2]) / self.temperature)([q, k])\n",
    "        if mask is not None:\n",
    "            attn = Add()([attn, Lambda(lambda x: (-1e+10) * (1 - x))(mask)])\n",
    "        attn = Activation('softmax')(attn)\n",
    "        attn = self.dropout(attn)\n",
    "        output = Lambda(lambda x: K.batch_dot(x[0], x[1]))([attn, v])\n",
    "        return output, attn\n",
    "\n",
    "# implement multi-head attention using dot product attention\n",
    "class MultiHeadAttention():\n",
    "    # mode 0 - big martixes, faster; mode 1 - more clear implementation\n",
    "    def __init__(self, num_head=15, dim=100, num_key=64, num_val=64, dropout=0.1):\n",
    "        self.num_head = num_head\n",
    "        self.dim = dim\n",
    "        self.num_key = num_key\n",
    "        self.num_val = num_val\n",
    "        self.dropout = dropout\n",
    "        self.qlayer = Dense(num_head * num_key, use_bias=False)\n",
    "        self.klayer = Dense(num_head * num_key, use_bias=False)\n",
    "        self.vlayer = Dense(num_head * num_val, use_bias=False)\n",
    "        self.attention = Attention(dim)\n",
    "        self.layer_norm = LayerNormalization()\n",
    "        self.w_o = TimeDistributed(Dense(dim))\n",
    "\n",
    "    def __call__(self, q, k, v, mask=None):\n",
    "        ql = self.qlayer(q)   # [batch_size, len_q, num_head * num_key]\n",
    "        kl = self.klayer(k)\n",
    "        vl = self.vlayer(v)\n",
    "\n",
    "        def reshape1(x):\n",
    "            s = tf.shape(x)   # [batch_size, len_q, num_head * num_key]\n",
    "            x = tf.reshape(x, [s[0], s[1], self.num_head, self.num_key])\n",
    "            x = tf.transpose(x, [2, 0, 1, 3])  \n",
    "            x = tf.reshape(x, [-1, s[1], self.num_key])  # [num_head * batch_size, len_q, num_key]\n",
    "            return x\n",
    "        \n",
    "        ql = Lambda(reshape1)(ql)\n",
    "        kl = Lambda(reshape1)(kl)\n",
    "        vl = Lambda(reshape1)(vl)\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = Lambda(lambda x: K.repeat_elements(x, self.num_head, 0))(mask)\n",
    "        head, attn = self.attention(ql, kl, vl, mask=mask)  \n",
    "                \n",
    "        def reshape2(x):\n",
    "            s = tf.shape(x)   # [num_head * batch_size, len_v, num_val]\n",
    "            x = tf.reshape(x, [self.num_head, -1, s[1], s[2]]) \n",
    "            x = tf.transpose(x, [1, 2, 0, 3])\n",
    "            x = tf.reshape(x, [-1, s[1], self.num_head * self.num_val])  # [batch_size, len_v, num_head * num_val]\n",
    "            return x\n",
    "        \n",
    "        head = Lambda(reshape2)(head)\n",
    "\n",
    "        outputs = self.w_o(head)\n",
    "        outputs = Dropout(self.dropout)(outputs)\n",
    "\n",
    "        return self.layer_norm(outputs), attn\n",
    "\n",
    "# Bidirectional LSTM with multihead attention (embedded matrix from spacy model)\n",
    "def bilstm_attn(embedding_size, embedding_dim, embedding_matrix, question_dim, answer_dim, num_class=1, dropout=0.1):         \n",
    "    input_q = Input(shape=(question_dim,), dtype=\"int32\")          \n",
    "    input_a = Input(shape=(answer_dim,), dtype=\"int32\")\n",
    "    xq = Embedding(embedding_size, embedding_dim, embeddings_initializer= tf.keras.initializers.Constant(embedding_matrix), input_length=question_dim, trainable=False)(input_q)   \n",
    "    xa = Embedding(embedding_size, embedding_dim, embeddings_initializer= tf.keras.initializers.Constant(embedding_matrix), input_length=answer_dim, trainable=False)(input_a)  \n",
    "    \n",
    "    # Parallel BiLSTM layers with attention\n",
    "    xq = Bidirectional(LSTM(question_dim, return_sequences=True))(xq)\n",
    "    xq = Bidirectional(LSTM(question_dim, return_sequences=True))(xq)\n",
    "    xa = Bidirectional(LSTM(answer_dim, return_sequences=True))(xa)\n",
    "    xa = Bidirectional(LSTM(answer_dim, return_sequences=True))(xa)\n",
    "    \n",
    "    # Attention Layer\n",
    "    xq, attn_q = MultiHeadAttention(num_head=15, num_key=question_dim, num_val=question_dim, dropout=dropout)(xq, xq, xq)\n",
    "    avg1d_q = GlobalAveragePooling1D()(xq)\n",
    "    max1d_q = GlobalMaxPooling1D()(xq)\n",
    "    \n",
    "    xa, attn_a = MultiHeadAttention(num_head=15, num_key=answer_dim, num_val=answer_dim, dropout=dropout)(xa, xa, xa)\n",
    "    avg1d_a = GlobalAveragePooling1D()(xa)\n",
    "    max1d_a = GlobalMaxPooling1D()(xa)\n",
    "    \n",
    "    x = Concatenate()([avg1d_q, max1d_q, avg1d_a, max1d_a])\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(num_class, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=[input_q, input_a], outputs=x)\n",
    "    model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "    # model.compile(tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True), 'binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Model History\n",
    "def plot(epochs, history):\n",
    "    xdata = list(range(1, epochs + 1))\n",
    "    plt.plot(xdata, history['accuracy'],      label='Train Acc')\n",
    "    plt.plot(xdata, history['val_accuracy'],  label='Val Acc')\n",
    "    plt.plot(xdata, history['loss'],     label='Train Loss')\n",
    "    plt.plot(xdata, history['val_loss'], label='Val Loss')\n",
    " \n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy/Loss\")\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample shapes: qst=(872422, 35), ans=(872422, 200), lab=(872422, 1)\n",
      "train  shapes: qst=(697937, 35), ans=(697937, 200), lab=(697937, 1)\n",
      "val    shapes: qst=(174485, 35), ans=(174485, 200), lab=(174485, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split training data for test and validation\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 64\n",
    "qst[qst < 0] = 0\n",
    "ans[ans < 0] = 0\n",
    "# Split training data 80/20 train/test split (include original unscaled labels for spearman rho correlation)\n",
    "qst_train, qst_val, ans_train, ans_val, lab_train, lab_val = train_test_split(qst, ans, lab, test_size=0.2, random_state=seed)\n",
    "print(\"sample shapes: qst={}, ans={}, lab={}\".format(qst.shape, ans.shape, lab.shape))\n",
    "print(\"train  shapes: qst={}, ans={}, lab={}\".format(qst_train.shape, ans_train.shape, lab_train.shape))\n",
    "print(\"val    shapes: qst={}, ans={}, lab={}\".format(qst_val.shape, ans_val.shape, lab_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Epoch 1/5\n",
      "10906/10906 [==============================] - 4766s 437ms/step - loss: 0.2659 - accuracy: 0.8839 - val_loss: 0.2511 - val_accuracy: 0.8895\n",
      "Epoch 2/5\n",
      "10906/10906 [==============================] - 4753s 436ms/step - loss: 0.2278 - accuracy: 0.9034 - val_loss: 0.2475 - val_accuracy: 0.9011\n",
      "Epoch 3/5\n",
      "10906/10906 [==============================] - 4738s 434ms/step - loss: 0.2050 - accuracy: 0.9140 - val_loss: 0.2371 - val_accuracy: 0.9044\n",
      "Epoch 4/5\n",
      "10906/10906 [==============================] - 4742s 435ms/step - loss: 0.1867 - accuracy: 0.9226 - val_loss: 0.2457 - val_accuracy: 0.9070\n",
      "Epoch 5/5\n",
      "10906/10906 [==============================] - 4754s 436ms/step - loss: 0.1679 - accuracy: 0.9313 - val_loss: 0.2568 - val_accuracy: 0.9057\n",
      "\n",
      "BiLSTM TRAINING AND VALIDATION COMPLETE... elapsed time: 23778.783109664917 sec\n"
     ]
    }
   ],
   "source": [
    "# train BiLSTM model\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))\n",
    "start_time = time.time()  \n",
    "bilstm_attn_model = bilstm_attn(embedding_shape[0], embedding_shape[1], embedding_matrix, max_question_len, max_answer_len)\n",
    "history = bilstm_attn_model.fit([qst_train, ans_train], lab_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=([qst_val, ans_val], lab_val))\n",
    "print('\\nBiLSTM TRAINING AND VALIDATION COMPLETE... elapsed time: {} sec'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{'loss': [0.2659124433994293, 0.2277822047472, 0.20499177277088165, 0.1866578906774521, 0.16794462502002716], 'accuracy': [0.8839107155799866, 0.9034482836723328, 0.9139865040779114, 0.9225560426712036, 0.9312888979911804], 'val_loss': [0.2511454224586487, 0.24750690162181854, 0.23705878853797913, 0.24569517374038696, 0.25679686665534973], 'val_accuracy': [0.8895263075828552, 0.9011490941047668, 0.9043928980827332, 0.9069948792457581, 0.9057111144065857]}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n\")\n",
    "print(history.history)\n",
    "print(\"\\n\")\n",
    "plot(EPOCHS, history.history)\n",
    "bilstm_attn_model.save_weights('tfqa_bilstm_attn_model_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
